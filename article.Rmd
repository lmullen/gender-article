---
title: "Jane, John … Leslie? A Historical Method for Algorithmic Gender Detection"
author: "Cameron Blevins and Lincoln Mullen"
output: html_document
---

```{r load-libraries, include=FALSE}
library(genderdata)
library(gender)
library(dplyr)
library(ggplot2)
library(mullenMisc)
library(knitr)
library(scales)

# TRUE to show code and warnings; FALSE to remove them for publication
display_code_blocks(FALSE)

# Add a thousands separator
knit_hooks$set(inline = function(x) {
  prettyNum(x, big.mark=",")
})

```

### Abstract

This paper addresses two trends in the humanities: the rise of gender as an analytical tool and the proliferation of large, machine-readable datasets. It outlines a new method for algorithmically inferring the gender of a name from historical data in order to take into account how naming practices change over time and space. In contrast to existing methods of predicting gender, this method provides a higher level of accuracy and a precise statement of the likelihood that a name is a given gender. The article describes the methodology as implemented in the [Gender](https://github.com/ropensci/gender) package for the [R programming language](http://www.r-project.org/). The article demonstrates the method's utility by applying it to a case study in which we study gender in the history profession by inferring the gender of authors of history dissertations and of authors and reviewers in the *American Historical Review*.

### Introduction: The "Leslie" Problem
 
As historians and other humanities researchers grapple with larger and larger datasets, they are increasingly using algorithms not just to extract information from existing data but to infer additional information from the data that is available.^[CITE: find example – network analysis, maybe http://kieranhealy.org/blog/archives/2013/06/09/using-metadata-to-find-paul-revere/] Datasets of interest to historians---for example membership lists, company payrolls, military rosters, passenger bookings, records of correspondence, and lists of published works---might included records with the names of individual people. Some datasets might contain associated information like a person's address, age, or rank. Other datasets contain little more than a personal name. Given large but sparse datasets, researchers have to use their ingenuity to derive additional kinds of information. What kind of information can researchers infer from just a name? Most obviously first names often imply a person's gender. "Jane Fay" is almost certainly a woman, while her brother "John Fay" is almost certainly a man. A straightforward computer program can infer their respective genders with relative ease.
 
The problem arises from the fact that the link between gender and naming practices, like language itself, is not static. What about Jane and John Fay's sibling, Leslie? If Leslie was born in the past sixty years, chances are good that Leslie would be their sister. But if the three siblings were born in the early twentieth century, chances are good that Leslie would be their brother. That is because the gendered naming convention surrounding "Leslie" completely changed over the course of one hundred years. 92% of the babies born in the United States in 1900 who were named “Leslie” were male, while 96% of those identically named babies born in the year 2000 were female.


```{r leslie}
# We cannot simply use the Social Security figures (even though they probably
# don't present a particular problem for the name Leslie) because later we will
# argue that the gender ratios for the SSA figures before 1930 are skewed. So we
# are going to splice the IPUMS data from before 1930 and the SSA data from
# after 1930.

ipums_leslie <- genderdata::ipums_usa %>%
  filter(name == "leslie", year <= 1930) 

ssa_leslie <- genderdata::ssa_national %>%
  filter(name == "leslie", year > 1930)

leslie_df <- rbind(ipums_leslie, ssa_leslie) %>%
  mutate(prop_female = female / (female + male)) 
  
leslie_plot <- leslie_df %>% 
  ggplot(aes(x = year, y = prop_female)) +
  geom_smooth() + 
  geom_point() +
  ggtitle("Proportion of female uses of the name 'Leslie,' 1820-2012") +
  xlab(NULL) + ylab(NULL) + ylim(0, 1) +
  geom_hline(yintercept = 0.5) + 
  annotate("text", x = 1900, y = 0.45, label = "Male") +
  annotate("text", x = 1900, y = 0.55, label = "Female") 

leslie_plot %>%
  gg_attribution("Data: IPUMS USA; Social Security Administration") %>%
  print()
```

Many other names as used in the United States, such as Madison, Morgan, Sydney, and Kendall, have also changed genders. Such changes in the prevailing gender of a name usually follow set patterns. In general, names tend to shift from being predominantly male to being predominantly female; the shift rarely happens in the other direction. In general, names that move from male to female also change from being unpopular to popular names. For example the name Madison changed from male to female suddenly after the 1985 because the name became extremely popular for naming baby girls, whereas before it had been an infrequently used male name. In other words, since the late twentieth century US at any rate, girls are more likely than boys to be receive a trendy name, and once a trendy name is associated with females it is unlikely to be used for males. The few exceptions of names which go from being female to male, such as Jan, have a different causal mechanism. It seems likely that Jan as an English name is female but that Jan as a Scandinavian name is male. Because the name has remained relatively uncommong, other causes besides changing gender preferences can explain the change.

```{r plot_names_that_change}
plot_names <-  c("madison",
                 "keanu",
                 "addison",
                 "jan",
                 "sydney",
                 "morgan",
                 "leslie",
                 "kendall")

selected_names_plot <- ssa_national %>%
  filter(name %in% plot_names) %>%
  mutate(prop_female = female / (female + male)) %>%
ggplot(aes(x = year, y = prop_female, color = name)) +
  geom_smooth(se = FALSE) +
  ggtitle("Changes in selected names, 1930-2012") +
  xlim(1930, 2012) + 
  xlab(NULL) + ylab(NULL) + ylim(0, 1) +
  geom_hline(yintercept = 0.5) +
  annotate("text", x = 1965, y = 0.45, label = "Male") +
  annotate("text", x = 1965, y = 0.55, label = "Female") 

selected_names_plot %>%
  gg_attribution("Data: Social Security Administration") %>%
  print()
```

For researchers working on contemporary subjects the "Leslie" problem is not an especially pressing one. An education policy analyst studying the demographics of different urban school districts, for instance, can turn to a variety of tools that use current databases of names, and these tools will likely identify the gender of Leslie Fay correctly. For example, the [Genderize.io](http://genderize.io/) online service determines the gender of first names "from user profiles across major social networks." Checking the service for the name Leslie returns a prediction that the name is female, along with an estimate of what proportion of the uses among members of unnamed social media sites is female and male.^[In this example the Genderize.io service has been accessed through the Gender package described below.]

```{r genderize, echo=TRUE, results='markup'}
gender("Leslie", method = "genderize")
```

Researchers studying historical subjects, on the other hand, need to take into account changes in naming practices. If that same researcher wanted to compare the demographics of contemporary urban schools with those from the early twentieth century, contemporary datasets would misidentify Leslie Fay's gender. The "Leslie" problem is not just for researchers who think of themselves as historians. Anyone studying a timeframe longer than a few years, or anyone studying a group whose characteristics do not match the probably unknowable characteristics of the groups that comprise social media datasets will also encounter this problem. As of 2012, the average American has a lifespan of nearly seventy-nine years–--more than enough time for naming practices to change quite dramatically.^[CITATION] Predicting gender from first names therefore requires a fundamentally historical method.
 
Our solution to the "Leslie" problem is to create a software package that combines a predictive algorithm with a range of historical dataset suitable to various times and regions. The algorithm calculates the proportion of male or female uses of a name in a given birth year or range of years. It thus can provide not only a prediction of the gender of a name, but also an estimate of how likely that prediction is. For example 52 percent of the babies named Leslie born in the United States in 1950 were girls and 48% were boys. This allows researchers to conduct more nuanced analysis and to determine for themselves what proportion is acceptable for making a prediction of male or female.

We recognize that gender is a fluid concept, both today and in the past, and that this method glosses over the complexities of historical definitions of gender and of the relationship between biological sex and gender. In some sense this is unavoidable since the large datasets which make this kind of analysis possible for the past were created by state agencies. For the category of gender (as for race) states have offered a limited number of boxes to check, and those boxes extert a tremendous power to define.^[CITE e.g. Margot Canady, The Straight State; works on e.g. Virginia’s definition of race. Shane Landrum on birth certificates. James C. Scott on Seeing Like a State or is that obvious to everyone by now?] Nevertheless, this method is suitable for two reasons. First, researchers are likely to use this method in the aggregate rather than for individuals. The assumption that a name implies male or female (and that those are possible categories to be inferred) is more valid when applied to large groups of people than it does when applied to individuals. Second, this method is neutral as to what the categories male or female actually mean in any given historical context. Researchers are free---indeed, obligated---to make that determination for themselves, and this package provides access to the underlying dataset so that researchers can interrogate every assumption we have made. This method does not argue against the complexities of historical understandings of gender, but as with any project it does require researchers who use the method to think through how the data was gathered, what it implies, and how it reflects social and cultural practices.
 
The remainder of this article is divided into two sections. First, we describe our method in more detail, compare it to existing methods, and explain how to use the method. Second, we apply the method to a case study of the historical profession in order to demonstrate the usefulness of the method.
 
### I. The Method

```{r calc_unique_names}
# Numbers of unique names in different data sets, for reference below
unique_names <- function(dataset) {
  dataset$name %>% unique %>% length
  }
  
kantrowitz_unique <- unique_names(genderdata::kantrowitz)
ssa_unique <- unique_names(genderdata::ssa_national)
ipums_unique <- unique_names(genderdata::ipums_usa)
```

Our historical method for inferring gender from names may be compared to a method available in the [Natural Language Toolkit](http://www.nltk.org/) for Python.^[Steven Bird, Edward Loper, and Ewan Klein, *Natural Language Processing with Python* (O’Reilly, 2009), ch. 2. Chapter 6 of the NLTK book also describes a method of predicting gender from the last letter of the name, but this example is given for the sake of explaining supervised classification and not as an end in itself, so we do not have reason to address this ahistorical method.] The NLTK is an influential software package for scholarship because it provides an extraordinary range of tools for analyzing natural language. Included in the NLTK are two lists of male and female names created by the computer scientist Mark Kantrowitz with assistance from Bill Ross.^[The [original lists of names](http://www.cs.cmu.edu/afs/cs/project/ai-repository/ai/areas/nlp/corpora/names/0.html) are available at the website of the computer science department at Carnegie Mellon University, and the NLTK implementation is described in its [documentation](http://www.nltk.org/howto/corpus.html).] These lists include `r kantrowitz_unique` unique names. Using the Kantrowitz names corpus in the NLTK, one could look up a name like Jane or John and find out that it is male or female. The Kantrowitz corpuse provides the list of names.^[The examples below is drawn from our Gender package which implements the Kantrowitz dataset for comparsion's sake, though its use is not recommended for actual research. The Gender package combines the Kantrowitz corpus's two lists into a single list, identifying names that are ambiguous because they appear on both lists as `"either"`.] 

```{r kantrowitz list, echo=TRUE, results='markup'}
genderdata::kantrowitz
```

One can then easily write a function which looks up the gender of a given name.

```{r abby-kantrowitz, echo=TRUE, results='markup'}
gender("abby", method = "kantrowitz")
```

```{r compare-kantrowitz-ssa, cache=TRUE, eval=FALSE}
# Calculate the error rate of the Kantrowitz data set. This code is very slow, 
# so I have disabled evaluating and hardcoded the value into the text for now.
# We can re-run this for the final version of the article.
cf_kantrowitz_ssa <- data.frame(name = unique(genderdata::kantrowitz$name),
                                stringsAsFactors = "FALSE")

# For just the names in the Kantrowitz corpus, predict the gender with both the Kantrowitz and the SSA method.
cf_kantrowitz_ssa <- cf_kantrowitz_ssa %>%
  group_by(name) %>%
  do(kantrowitz = gender(name = .$name, method = "kantrowitz")$gender,
     ssa = gender(name = .$name, method = "ssa")$gender)

cf_results <- as.character(cf_kantrowitz_ssa$kantrowitz) ==
  as.character(cf_kantrowitz_ssa$ssa)

# Error rate is the number of mismatches to the total number of names
kantrowitz_error_rate <- 1 -(sum(cf_results) / length(cf_results))
```

```{r}
# Hardcode the error rate for now. This value is based on running the code above
# locally.
kantrowitz_error_rate <- 0.2325766
```

The most significant problem with the Kantrowitz names corpus and thus the NLTK implementation is that it assumes that names are timeless. As pointed out above, this makes the corpus unusable for historical purposes. Furthermore the corpus includes some oddities which make it less than suitable. Some names like Abby are overwhelmingly female and some like Bill are overwhelmingly male, but the corpus includes them as both male and female. The Kantrowitz corpus contains only `r kantrowitz_unique`, a mere `r percent(kantrowitz_unique / ssa_unique)` of the `r ssa_unique` names in the Social Security Administration dataset and `r percent(kantrowitz_unique / ipums_unique)` of the `r ipums_unique` names in the census records provided by IPUMS USA. There are therefore many names that it cannot identify. Assuming for the moment that our method provides more accurate results, we estimate that `r percent(kantrowitz_error_rate)` percent of the names in the Kantrowitz corpuse are misclassified or classified as ambigious when a valid prediction could be made.

We mention the Kantrowitz name corpus as implemented in NLTK because the Natural Language Toolkit is rightly regarded as influential for scholarship. Its flaws are also typical of the problems with most other implementations of gender prediction algorithms. The Genderize.io API is, for example, a more sophisticated implementation of gender prediction than the NLTK algorithm. Besides predicting male or female for gender, it also reports the proportion of male or female names, along with a count of the number of uses of the name that it is basing its prediction on. Genderize will also permit the user to customization a prediction for different countries: an extremely important feature. Genderize.io reports that its "database contains 142848 distinct names across 77 countries and 85 languages." Genderize is unsuitable for historical work, however, because it is based only on contemporary data. According to the documentation for its API, "It utilizes big datasets of information, from user profiles across major social networks."^[Quotations are taken from the [Genderize.io website](http://genderize.io), with correspondence from the developer behind the site for confirmation.] It would be anachronistic to apply these datasets to the past, and Genderize.io provides no functionality to filter results chronologically as it does geographically. In addition, exactly what the dataset comprises and how it was gathered is unclear, which keeps scholars from interrogating the value of the source.

R and Python are the most commonly used languages for data analysis among digital humanists. Python's existing packages for gender prediction all implement a method similar to the NLTK or Genderize.io.^[Python library names] To our knowledge, [CRAN](http://cran.rstudio.com/) (the central repository for R packages) does not include any packages dedicated to gender prediction. Though options abound for geocoding, for example, there is no satisfactory existing method of gender prediction for historical and humanistic research.

To that end we have created the [Gender](https://github.com/ropensci/gender) package for R which contains the predictive algorithm, and an associated [genderdata](https://github.com/lmullen/gender-data-pkg) package which contains various historical datasets. This R implementation is based on an [earlier Python implementation](https://github.com/cblevins/Gender-ID-By-Time) by [Cameron Blevins](http://www.cameronblevins.org/) and [Bridget Baird](http://www.conncoll.edu/directories/emeritus-faculty/bridget-baird/). 

The possibilities for encoding gender from names depends on two things. First, it depends on having a suitable (and suitably large) dataset for the time period and region under study. Unsurprisingly such datasets are almost always gathered in the first instance by states, though the compilation and digitization may be undertaken by scholarly researchers. Second, it depends on a suitable algorithm for estimating the proportion of male and female names for a given year, or range of years since often a person cannot be associated with an exact date. It is especially important that the algorithm take into account any biases in the data to make correct predictions. Development of the R package has had two primary aims. The first is to abstract the predictive algorithm to the simplest possible form so that it is usable for a wide range of historical problems rather than depending on the format of any particular data set. The second has been to provide as many datasets as possible in order to localize the predictions to particular times and places. To that end, [Ben Schmidt](http://benschmidt.org/) contributed a dataset of US Census Data and accompanying code, as well as providing a significant correction to predictions based on Social Security Administration data.
 
The Social Security Administration provides annual data on the names and genders of babies stretching back to the year 1880. This is database encompases 91,320 unique names. For comparison, [example of other databases and their size]. What makes it even more useful, however, is its temporal dimension. This allows a researcher to figure out not just the likelihood that “Leslie” is a male or female name, but the likelihood that “Leslie” is a male or female name for a specific range of years, or for a specific year.
 
Using for example the SSA data for a few names (once it has been munged into a more useful form). The columns male and female record the number of people of that gender (sex?) born in that year who received Social Security cards.
 
name         year    female     male
---------  ------  --------  -------
jane         1890       372        0
jane         1990       771        8
john         1890        56     8502
john         1990        81    29066
madison      1890         0       14
madison      1990      1407      145
 
Furthermore, we can calculate the proportions of male and female and on that basis guess the gender for a given year.
 
name         year    female     male    proportion_male    proportion_female  gender  
---------  ------  --------  -------  -----------------  -------------------  --------
jane         1890       372        0             0.0000               1.0000  female  
jane         1990       771        8             0.0103               0.9897  female  
john         1890        56     8502             0.9935               0.0065  male    
john         1990        81    29066             0.9972               0.0028  male    
madison      1890         0       14             1.0000               0.0000  male    
madison      1990      1407      145             0.0934               0.9066  female
ADD LESLIE AND ANOTHER EXAMPLES WE USE
 
Furthermore, one can specify a range of years and calculate the proportion for that time period.
 
Given this data set, it is simple to perform perform a merge (a join, in SQL terms) on either a name or a combination of name and year to link this data to a date set.
 
Our program is best understood through an example. Let’s say a historian is working with records from a public school system and wants to know what percentage of its total student body each year was male or female. This historian can tell the program the approximate age range of its target population - in this case, ages 4 to 18. Our program then iterates through all of the names attempting to identify their gender based on a) the date of the data, and b) the age range specified by the user. Sidney Dubner, for instance, was enrolled as a student in the year 1918. Given the age range of 4 to 18 specified by the user, the program guesses that Sidney Dubner was born between 1900 and 1914. It then looks up every birth of a child named “Sidney” recorded by the Social Security Administration between 1900 and 1914 and calculates that 94.7% of these babies named “Sidney” were male. Chances are good that this was a male student. But what if the year was 1998 instead of 1918? The chances that “Sidney” was a boy falls to 66.4%. Fast-forward another ten years to 2008, and suddenly it’s more likely that “Sidney” is in fact a girl, not a boy (69.3% female to 30.7% male).
 
Reference Implementations/Software:
 
Description of Lincoln’s R package [link].
 
Implements both the Kantrowitz method and this new method. Extensible through the addition of additional data sets as they become available.
Includes cleaned up, tidied (in the Hadley Wickham sense) versions the Kantrowitz data sets and the SSA national and state data. (Link to gender repo.) These allow researchers to load the package and use the data directly, in addition to accessing through methods. Furthermore
Allows for encoding of individual names by year, of data sets where each name is associated with a year, and data sets where there are names of years and a range of years is provided. Eventually will include ability to specify by
Samples of code:
 
find_gender(“madison”) # returns “female” and probability
find_gender(“madison”, 1990) # returns “female” and probability
find_gender(“madison”, 1890) # returns “male” and probability
 
year  name     
------  ---------
 1890  john     
 1990  john     
 1990  john     
 1890  jane     
 1990  jane     
 1890  madison  
 2012  madison
For data sets where there is no year available, you can specify the range.
find_gender(test_data, years = c(1880, 1940)) # returns male, male, male, male, female, female
 
For data sets where there is a year available, say a year of birth, then you can specify the column that stores that data, and each person will be looked up individually.
find_gender(test_data, year_column = T) # returns male, female, male, male, female, female
 
In cases where the data set includes non-birth date, and because those dates vary significantly, one wishes to operate on the basis of date, one is advised to split up the data into cohorts, apply the gender checking methods, then recombine the split up data sets. (This is akin to Wickhams Split Apply Combine method: citation to article.) In this example of the dissertations data sets, I have split the data set into people whose dissertations were before 1950 and those who were after. (In actual practice, I would use more fine grained cohorts, and a more sophisticated method for splitting and applying, such as the `ddply` command in `plyr`.)
 
library(dplyr)
dissertations_before_1950 <- dissertations %.%
 filter(year < 1950)
dissertations_after_1950 <- dissertations %.%
 filter(year >= 1950)
dissertations_before_1950 <- dissertations_before_1950 %.%
 find_gender(years = c(1880,1940)) # reasonable guess as to ages
dissertations_after_1950 <- dissertations_after_1950 %.%
 find_gender(years = c(1930,1990)) # reasonable guess as to ages
dissertations_combined < rbind(dissertations_before_1950, dissertations_after_1950)
 
 
Limitations:
 
 
On the methodological front, perhaps the program’s most glaring limitation is its weakness in inferring the gender of non-American names. Once again, this is a reflection of where the source data originated: U.S. government agencies. More recent datasets exist for non-American names, but we have been unable to find or incorporate information on how these names have changed over time. The program is extensible, however, meaning that if someone does locate a suitably temporal dataset of non-American names they can implement it into our program.
 
Our program uses source data that only goes back as far as 1880, making it a far more effective method for twentieth-century analysis. Additionally, our program is not as effective at identifying highly uncommon names. The annual reference data it uses from the Social Security Administration only includes baby names that occurred at least five times in a given year. If a name was never given to five or more babies over the course of any year from 1880 to the present, our program will not be able to infer its gender. [more details – see below?]
[- SSA restricts its data to only names with at least 5 occurrences (we’re still missing a bit of the long tail). Not a big problem because we still have more names, and more obscure names, than any other data set. More of a problem when localizing to the state, which starts in 1910 (double check) and because it includes only >5 occurrences in much smaller jurisdictions, more of the long tail is cut off.]
 
### II. Measuring Gatekeeping in the Historical Profession
 
In a 2005 report for the American Historical Association, Elizabeth Lunbeck acknowledged “a sea change in the [historical] profession with respect to gender” before going on to describe the painful limitations of this sea change for female historians: ongoing personal discrimination, lower salaries, and barriers to securing high-ranking positions. Lunbeck’s report drew in part on a survey of 362 female historians that produced a rich source of responses detailing the deep and multi-faceted challenges facing women in the profession. What follows is a quantitative supplement to Lunbeck’s analysis that uses our program to analyze gender representation amongst historians across a much larger scale and a much longer time period. http://www.historians.org/Documents/About%20AHA%20and%20Membership/CWH-Report_5.20.05.pdf
 
Our analysis focuses on one of the bedrocks of the historical profession: scholarly research. We begin with the history dissertation, often the defining scholarly output of a historian’s early career. The completion of a dissertation marks a standardized moment of transition out of the “training” phase of the historical profession. Data supplied by ProQuest provided roughly [80,000] PhD(?) dissertations completed since [1950]. Identifying the gender of their authors gives a sense for the number of women and men who are completing PhD-level training in history each year. Our program uses what year a historian wrote their dissertation to estimate a period for when they might have been born: a historian who completed their dissertation in 1980 was likely born between ____ and _____. Using this temporal information, we are better able to infer their gender and chart how the larger representation of women and men changes year-by-year. 
 
[chart – raw numbers]
 
Another way to examine this trend is to look at the proportion of male and female dissertation authors over time, which smoothes out changes in the absolute number of dissertations produced. The proportion of dissertations written by women has steadily increased over the past half-century, a change that began in the late 1960s and continued through the early 2000’s. Since that point, the proportion of dissertations written by women has largely plateaued at a few percentage points below the proportion written by men. Female historians have achieved something approaching parity with male historians in terms of how many women and women complete dissertations each year.
 
[chart - proportion]
 
But what happens after the dissertation? It is, after all, only the first major stage of a historian’s research output. The “coin of the realm” for many historians remains the publication of a scholarly monograph to be read and evaluated by peers. This process often takes the form of book reviews published in academic journals. One of the leading journals in the historical profession is the American Historical Review, the flagship journal of the American Historical Association. Along with a few dozen articles The AHR publishes five issues each year that contain, in aggregate, roughly one thousand books reviews covering (in its own words) “every major field of historical study.” The AHR is not only one of the widest-ranging journals in the profession, it is also the oldest; the journal has been publishing continuously since 1895. The range, scope, and length of the AHR makes it an ideal source to analyze the historical profession on a large scale.
 
We take the AHR as a rough proxy for gatekeeping within the larger historical profession. When a book appears in the AHR it serves as a signal that other historians in positions of power have “approved” it for consideration. This signal is not necessarily correlated with the quality of the book. Even if it garners a negative review, the fact that it appears in the journal at all is a measure of the fact that the profession’s gatekeepers have deemed it important enough to review. On the flip side, a book that does not appear in the AHR may have gone on to have a significant impact on the profession. It is precisely this professional gatekeeping dimension that makes the AHR useful to study in the context of gender representation.
 
Scraping the table-of-contents of every issue of the American Historical Review results in a dataset of close to 60,000 books reviewed by the journal since it began publication in 1895. Our program then inferred the gender of the authors of these books, which we could then use to plot the proportion of female and male authors over time. The temporal trajectory of gender representations roughly resembles that of history dissertations: women began making inroads in the late 1960s and have made steady gains over the past four decades. By the twenty-first century the proportion of female authors reviewed in the AHR had more than tripled.
 
[graphic]
 
But a closer look shows important differences between the proportion of women writing history dissertations and the proportion of women appearing in the AHR. Although both have trended upwards since the 1970s the slope is a lot steeper for dissertations than it is for the AHR. Female historians have very nearly closed the gaps in terms of newly completed dissertations, but the glass ceiling remains stubbornly low in terms of what happens from that point onwards. In book reviews published in the AHR male authors continue to outnumber female authors by a factor of nearly 2 to 1. The long-term gains made by female doctoral students do not carry over in the pages of the historical profession’s leading journal.
 
[chart comparing dissertations with AHR]
 
The path from a dissertation to an AHR book review is not an automatic one. Not all dissertations are published as books, not all books are submitted to the American Historical Review, and not all book submissions are accepted by the AHR editors for review. As of August 2014 the journal’s website reminds readers that “the AHR receives over 3,000 books a year; we have the resources to publish at most 1,000 reviews a year (approximately 200 per issue).” (http://www.indiana.edu/~ahrweb/book_review_guide.html - retrieved August 25 2014). Fewer and fewer female historians make it through each successive step. Establishing a single causal reason for this pattern is all but impossible, and instead a murky concoction of interrelated factors likely contributes to the gap. For one, a 2010 survey by the American Historical Association revealed the female historians dedicated substantially more time to child and elder care than their male colleagues, leaving less time for research. This gender gap is more likely to impact the production of a book than a dissertation, as graduate students are generally younger and less likely to be juggling child-rearing responsibilities while writing than their older peers. More insidiously, women continue to face insidious gender discrimination.
 
We then used our program to infer the gender of not just book authors reviewed by the AHR, but the gender of the reviewers themselves. The story is much the same for reviewers as it is for authors: more than than twice as many men as women appear as reviewers in the journal. But gender inflects book reviews in less direct ways by shaping who writes reviews of which book authors. About three times as many men write reviews of male-authored books as do women. In the case of female-authored books the ratio of female-to-male reviewers is much closer to 50/50. In short, women are much more likely to write reviews of other women. And while men still write the majority of reviews of female-authored books, they tend to gravitate more towards male authors – who are, of course, already over-represented in the AHR.
 
[chart: male authored books]
[chart: female authored books]
 
The American Historical Association also categorizes their reviews under different historical sub-fields. Although the journal’s taxonomy has changed quite a bit over time, it did allow us to refine our analysis. Were there more reviews of female authors in certain sub-fields rather than others, and has that changed over the past forty years? Caribbean/Latin American history has had something approaching equal representation for the past decade-and-a-half. In both African history and Ancient/Medieval history female historians made some quite dramatic gains during the late-nineties and aughts. The guiltiest parties, however, are also the two subject categories that publish the most book reviews in the AHR: Modern/Early Modern Europe and the United States/Canada. Both sub-fields have made progress over the four decades but still hover at around two-thirds male. Gender representation is not evenly distributed across the profession.
 
[chart – sub-fields]
 
One 2013 analysis of 2,500 recent history Ph.D.’s found that “gender played little role in employment patterns across particular professions and industries.” (http://historians.org/Documents/Many_Careers_of_History_PhDs_Final.pdf) Our own analysis reveals a more complicated reality. The flagship journal of professional historians continues to publish twice as many reviews of books by female authors as male authors. This disparity is put into even sharper relief when set against the relative parity achieved by women in producing history dissertations. Women might be getting hired at comparable rates to men, but discriminatory gatekeeping remains alive and well in the historical profession. Our program allows us to quantitatively measure the scope of the problem on a large scale, how it’s changed over time, and what remains to be done.
 
### Conclusion
 
Our contributions:

-     Broadly: gender studies + big data
-   	Temporal dimension makes it better suited to fit the needs of humanities research than contemporary approaches – both more accurate (historical) and more nuanced (supplying the gendered proportion of a name for different periods)
-   	Extensible – non US-names, older names. (future work)
 
The fundamental points are that we have a much larger corpus of names. More importantly the ability to vary the look up based on a specific date of birth or a specified range of dates. Making this much more useful for historians, but also for any research in any field, given that the normal human lifespan present in any data set means that names can vary as much as a century, and so everyone needs to be using a fundamentally historical method. (Take that, sociologists.)
 
Future work:
 
Both the Python script and the R package are easily extensible to allow additional data sets, say from other countries. (Are there other data sets, say for Great Britain, http://data.gov.uk/data/search?q=names ??) And eventually perhaps US census data, which would solve the 19th century problem.
 

----

Things cut to be moved to more suitable places:

[NOTE: The SSA data includes only names used more than 5 times in a given year, so the "long tail" of actual number of names in the US is considerably larger. Link to SSA data.]
